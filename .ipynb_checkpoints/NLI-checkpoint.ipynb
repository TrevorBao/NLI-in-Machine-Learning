{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315aa99a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! pip install --upgrade tensorflow\n",
    "# ! pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29faab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Layer, Input, Embedding, Bidirectional, LSTM, Dense, Dropout, concatenate, GlobalMaxPooling1D, GRU\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51d5551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "validation_data = pd.read_csv('dev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e832d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert text columns to strings and handle NaN values\n",
    "# data['premise'] = data['premise'].astype(str).fillna('<NAN>')\n",
    "# data['hypothesis'] = data['hypothesis'].astype(str).fillna('<NAN>')\n",
    "# validation_data['premise'] = validation_data['premise'].astype(str).fillna('<NAN>')\n",
    "# validation_data['hypothesis'] = validation_data['hypothesis'].astype(str).fillna('<NAN>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4ba7620",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable()\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, my_custom_arg=42, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "        self.my_custom_arg = my_custom_arg\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='attention_weight', \n",
    "                                 shape=(input_shape[-1], 1),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(name='attention_bias',\n",
    "                                 shape=(input_shape[1], 1),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        return output\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(AttentionLayer, self).get_config()\n",
    "        config.update({\n",
    "            'my_custom_arg': self.my_custom_arg,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19241d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare SentenceTransformer model for embeddings\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "def generate_embeddings(dataframe, model):\n",
    "    premise_embeddings = model.encode(dataframe['premise'].tolist(), show_progress_bar=True)\n",
    "    hypothesis_embeddings = model.encode(dataframe['hypothesis'].tolist(), show_progress_bar=True)\n",
    "    embeddings = np.concatenate((premise_embeddings, hypothesis_embeddings), axis=1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f1838d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfe54b9fe3d4f91b9d387769cc3e93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/842 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf4b2eb88764b2cbb14e5c350854626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/842 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2b885df5a741deaec38811a5942a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3629eb7aca42a9a4e4240c89b56786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate embeddings\n",
    "train_embeddings = generate_embeddings(data, sentence_model)\n",
    "validation_embeddings = generate_embeddings(validation_data, sentence_model)\n",
    "\n",
    "train_labels = data['label'].values\n",
    "validation_labels = validation_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a177391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "def create_model(embedding_dim):\n",
    "    input_shape = (embedding_dim,)\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # Bi-GRU with Attention\n",
    "    reshape_layer = tf.keras.layers.Reshape((1, -1))(input_layer)\n",
    "    bi_gru = Bidirectional(GRU(64, return_sequences=True))(reshape_layer)\n",
    "    attention_output = AttentionLayer()(bi_gru)\n",
    "    max_pooling = GlobalMaxPooling1D()(attention_output)\n",
    "    \n",
    "    # Classification layers\n",
    "    dense_layer = Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(max_pooling)\n",
    "    dropout_layer = Dropout(0.5)(dense_layer)\n",
    "    predictions = Dense(1, activation='sigmoid')(dropout_layer)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6793945",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = sentence_model.get_sentence_embedding_dimension() * 2\n",
    "model = create_model(embedding_dim)\n",
    "model.compile(optimizer=Adam(learning_rate=0.00035), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a0eaed0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add learning rate reduction\n",
    "PATIENCE = 3\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                                             patience=PATIENCE,\n",
    "                                             verbose=1,\n",
    "                                             factor=0.5,\n",
    "                                             min_lr=0.0000001)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               patience=PATIENCE,\n",
    "                               verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e028317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate unique file paths for model checkpoints\n",
    "def create_unique_checkpoint_file(base_dir):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    filename = f'model_checkpoint_{timestamp}.keras'\n",
    "    unique_file_path = os.path.join(base_dir, filename)\n",
    "    return unique_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "43304cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Create a model checkpoint callback with a unique file path for each checkpoint\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=create_unique_checkpoint_file(temp_dir),\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks_list = [learning_rate_reduction, early_stopping, model_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "091d4437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m823/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6281 - loss: 1.0329\n",
      "Epoch 1: val_loss improved from inf to 0.62202, saving model to C:\\Users\\ttt\\AppData\\Local\\Temp\\tmp8rsxsj04\\model_checkpoint_20240420-181030.keras\n",
      "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6287 - loss: 1.0275 - val_accuracy: 0.6629 - val_loss: 0.6220 - learning_rate: 3.5000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6844 - loss: 0.6057\n",
      "Epoch 2: val_loss improved from 0.62202 to 0.60731, saving model to C:\\Users\\ttt\\AppData\\Local\\Temp\\tmp8rsxsj04\\model_checkpoint_20240420-181030.keras\n",
      "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6844 - loss: 0.6057 - val_accuracy: 0.6730 - val_loss: 0.6073 - learning_rate: 3.5000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m813/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6898 - loss: 0.5985\n",
      "Epoch 3: val_loss improved from 0.60731 to 0.60058, saving model to C:\\Users\\ttt\\AppData\\Local\\Temp\\tmp8rsxsj04\\model_checkpoint_20240420-181030.keras\n",
      "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6899 - loss: 0.5983 - val_accuracy: 0.6739 - val_loss: 0.6006 - learning_rate: 3.5000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m841/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6953 - loss: 0.5859\n",
      "Epoch 4: val_loss improved from 0.60058 to 0.59402, saving model to C:\\Users\\ttt\\AppData\\Local\\Temp\\tmp8rsxsj04\\model_checkpoint_20240420-181030.keras\n",
      "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6953 - loss: 0.5859 - val_accuracy: 0.6758 - val_loss: 0.5940 - learning_rate: 3.5000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m835/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6997 - loss: 0.5775\n",
      "Epoch 5: val_loss improved from 0.59402 to 0.59168, saving model to C:\\Users\\ttt\\AppData\\Local\\Temp\\tmp8rsxsj04\\model_checkpoint_20240420-181030.keras\n",
      "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6997 - loss: 0.5775 - val_accuracy: 0.6838 - val_loss: 0.5917 - learning_rate: 3.5000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m811/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6956 - loss: 0.5764\n",
      "Epoch 6: val_loss did not improve from 0.59168\n",
      "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6957 - loss: 0.5763 - val_accuracy: 0.6764 - val_loss: 0.5919 - learning_rate: 3.5000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7010 - loss: 0.5667\n",
      "Epoch 7: val_loss improved from 0.59168 to 0.58796, saving model to C:\\Users\\ttt\\AppData\\Local\\Temp\\tmp8rsxsj04\\model_checkpoint_20240420-181030.keras\n",
      "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7010 - loss: 0.5667 - val_accuracy: 0.6834 - val_loss: 0.5880 - learning_rate: 3.5000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m831/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7066 - loss: 0.5619\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.58796\n",
      "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7065 - loss: 0.5620 - val_accuracy: 0.6803 - val_loss: 0.5888 - learning_rate: 3.5000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m833/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7008 - loss: 0.5639\n",
      "Epoch 9: val_loss did not improve from 0.58796\n",
      "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7008 - loss: 0.5639 - val_accuracy: 0.6798 - val_loss: 0.5890 - learning_rate: 1.7500e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m840/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7054 - loss: 0.5639\n",
      "Epoch 10: val_loss did not improve from 0.58796\n",
      "\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7054 - loss: 0.5639 - val_accuracy: 0.6843 - val_loss: 0.5907 - learning_rate: 1.7500e-04\n",
      "Epoch 10: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "history = model.fit(\n",
    "                    train_embeddings, \n",
    "                    train_labels, \n",
    "                    epochs=50, \n",
    "                    batch_size=32, \n",
    "                    validation_data=(validation_embeddings, validation_labels),\n",
    "                    callbacks=callbacks_list\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4e1fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('GRUModel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e97b407",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A total of 1 objects could not be loaded. Example error message for object <GRUCell name=gru_cell, built=True>:\n\nLayer 'gru_cell' expected 3 variables, but received 0 variables during loading. Expected: ['kernel', 'recurrent_kernel', 'bias']\n\nList of objects that could not be loaded:\n[<GRUCell name=gru_cell, built=True>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_checkpoint_20240420-181030.keras\u001b[39m\u001b[38;5;124m'\u001b[39m, custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttentionLayer\u001b[39m\u001b[38;5;124m'\u001b[39m: AttentionLayer})\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:176\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    173\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip:\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    177\u001b[0m         filepath,\n\u001b[0;32m    178\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    180\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(filepath)\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:152\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    150\u001b[0m     )\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_model_from_fileobj(\n\u001b[0;32m    153\u001b[0m         f, custom_objects, \u001b[38;5;28mcompile\u001b[39m, safe_mode\n\u001b[0;32m    154\u001b[0m     )\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:207\u001b[0m, in \u001b[0;36m_load_model_from_fileobj\u001b[1;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    204\u001b[0m         asset_store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m failed_trackables:\n\u001b[1;32m--> 207\u001b[0m         _raise_loading_failure(error_msgs)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:295\u001b[0m, in \u001b[0;36m_raise_loading_failure\u001b[1;34m(error_msgs, warn_only)\u001b[0m\n\u001b[0;32m    293\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: A total of 1 objects could not be loaded. Example error message for object <GRUCell name=gru_cell, built=True>:\n\nLayer 'gru_cell' expected 3 variables, but received 0 variables during loading. Expected: ['kernel', 'recurrent_kernel', 'bias']\n\nList of objects that could not be loaded:\n[<GRUCell name=gru_cell, built=True>]"
     ]
    }
   ],
   "source": [
    "load_model('model_checkpoint_20240420-181030.keras', custom_objects={'AttentionLayer': AttentionLayer}, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f4cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(validation_embeddings)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "predictions_df = pd.DataFrame(predicted_labels, columns = ['prediction'])\n",
    "predictions_df.to_csv('predictions_B.csv',index = False)\n",
    "\n",
    "accuracy = accuracy_score(validation_labels, predicted_labels)\n",
    "report = classification_report(validation_labels, predicted_labels)\n",
    "print(accuracy)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9973e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
